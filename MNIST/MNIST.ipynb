{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfaa12c-cab1-4be3-8099-3e4df70b297a",
   "metadata": {},
   "source": [
    "https://euske.github.io/introdl/lec6/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999bb1fd-ee93-4a47-aeef-cc2e25737907",
   "metadata": {},
   "source": [
    "GPU は CPU に比べて単純な処理しかできないが、CPU に比べて はるかに多くの処理を並列実行できるため、ある種のアルゴリズムに対しては CPU に比べて数倍〜数十倍の速度が出せる。ニューラルネットワークで 行われる演算はほとんどが足し算と掛け算なので、 とくに GPU で処理するのに向いているといえる.  \n",
    "NVIDIA が提供する CUDA 開発キットには GPU 用のコードが 生成できるよう拡張された C/C++コンパイラ (nvcc) が付属している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec31f914-275f-41f4-8557-da701177294b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1b8d2-eca3-4c95-9cd8-a79896ecba03",
   "metadata": {
    "tags": []
   },
   "source": [
    "機械学習における「テンソル」は「多次元配列」とほぼ同義である。 したがって Tensor型の基本機能も NumPy における ndarray型とほとんど同じであり、使い方もわざと ndarray型に似せてある。 ただし、以下のような機能が追加されている:\n",
    "\n",
    "Tensor上のデータは、CPU上の主記憶か、 あるいは GPU上のメモリのどちらに格納するか選ぶことができる。\n",
    "Tensor上の各数値は、 それが計算されたときの勾配 (grad) を保持することができる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74518fd8-06f7-4ffd-a3ce-3d240b35693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([1,2,3])  # x1はCPU上に作成される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0080c096-3a7e-4ae9-874c-fd2fc36b3c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48296838-2999-4b7c-9257-f039b44c9b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x1.to('cuda')          # x1をGPUに転送し、x2とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa03ab28-4918-4c97-8e04-a39246bbbc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b79e2153-384d-4794-a94f-dde8791374f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = x2.to('cpu')           # x2をCPUに転送し、x3とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdd674f8-6d73-4365-a806-1378c2eecd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c6d6db8-3430-4d9f-b175-5c06fcf929cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2*x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "328a2d3a-131b-48f3-89aa-c8b942f3a53e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx2\u001b[49m      \u001b[38;5;66;03m# CPU上とGPU上にあるデータは互いに計算できない。\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "x1*x2      # CPU上とGPU上にあるデータは互いに計算できない。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194b9c6d-2fcb-41d2-a6ed-a779c9c1d44f",
   "metadata": {},
   "source": [
    "## 演習6-5. CUDA を使ってテンソルを計算する (CUDA が使用可能な環境のみ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12dfedf2-b15b-4931-b075-e602e0dc7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# timeit: テンソルを二乗し、計算にかかった時間を表示する。\n",
    "def timeit(x):\n",
    "    t0 = time.time()\n",
    "    x = torch.mm(x, x)\n",
    "    dt = time.time() - t0\n",
    "    print(dt)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3c23c-09f7-40f9-817f-6583890ee981",
   "metadata": {},
   "source": [
    "CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30657b26-ad54-4895-9a5f-31b9ad6a33be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009909391403198242\n",
      "1.2529351711273193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2529351711273193"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100×100のランダムな行列を二乗する。\n",
    "x = torch.rand(100,100)\n",
    "timeit(x)\n",
    "# 10000×10000のランダムな行列を二乗する。\n",
    "x = torch.rand(10000,10000)\n",
    "timeit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722651a9-3862-482f-8513-2c9f08c8c351",
   "metadata": {},
   "source": [
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad676310-50a7-4b10-a5ca-dfe0153bb495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.179115295410156e-05\n",
      "0.00013184547424316406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00013184547424316406"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100×100のランダムな行列を二乗する。\n",
    "x = torch.rand(100,100).to('cuda')\n",
    "timeit(x)\n",
    "# 10000×10000のランダムな行列を二乗する。\n",
    "x = torch.rand(10000,10000).to('cuda')\n",
    "timeit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bafee4d-f6f8-45a4-9685-7f5e69da2f7e",
   "metadata": {},
   "source": [
    "## 3. PyTorch を使った MNIST の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af1fb-fb2c-44e6-af92-b5f1c071795b",
   "metadata": {},
   "source": [
    "https://github.com/jiuntian/pytorch-mnist-example/blob/master/pytorch-mnist.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de22e7a-5df8-40f5-ae53-90332b1da77b",
   "metadata": {},
   "source": [
    " PyTorch では、計算に使うテンソルが GPU 上にあれば GPU 上で計算が行われる。 そのため、以上のコードを GPU に対応させるのは容易である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb9540f5-4cb5-44e0-8ab3-c7732b6a8ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6746a6d-c2a0-4712-830a-905cd9dce47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12.9%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
    "## We create dataloader with dataset from torchvision, \n",
    "## and we dont have to download it seperately, all automatically done\n",
    "\n",
    "# Define batch size, batch size is how much data you feed for training in one iteration\n",
    "batch_size_train = 64 # We use a small batch size here for training\n",
    "batch_size_test = 1024 #\n",
    "\n",
    "# define how image transformed\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "#image datasets\n",
    "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                           train=True, \n",
    "                                           download=True,\n",
    "                                           transform=image_transform)\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                          train=False, \n",
    "                                          download=True,\n",
    "                                          transform=image_transform)\n",
    "#data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size_test, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be4f3a0-9fad-4761-82ee-1c479952ef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import matplotlib.pyplot as plt\n",
    "# We can check the dataloader\n",
    "_, (example_datas, labels) = next(enumerate(test_loader))\n",
    "sample = example_datas[0][0]\n",
    "# show the data\n",
    "plt.imshow(sample, cmap='gray', interpolation='none')\n",
    "print(\"Label: \"+ str(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5146c850-2c53-4321-a31e-c9a51dae4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start to build our CNN model\n",
    "## We first import the pytorch nn module and optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## Then define the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #input channel 1, output channel 10\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        #input channel 10, output channel 20\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        #dropout layer\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "668f31b4-3fdd-4b7e-b128-6ff5da5674a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model and optimizer\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "device = \"cuda\" #using cpu here\n",
    "model = CNN().to(device) #using cpu here\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df732290-6e18-4d27-aa26-2815021eee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9328bb8b-6c43-4fe1-b733-df18b463959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "##define train function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        tk0.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "##define test function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74b9ff59-3bb4-4c3b-9cee-396d46446a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/1895196525.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm(train_loader, total=int(len(train_loader)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7efc7b5773445681a55f99960aa498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/4020281764.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3616, Accuracy: 8877/10000 (89%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c0e7cabf2542f4a627ea326ed6512b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2464, Accuracy: 9284/10000 (93%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13042a909154681a7b3ed1780d6ca24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1860, Accuracy: 9475/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6752f035-4ad5-484a-99e4-7b7da1d1f650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3452f7e7-e6a2-41b1-932d-306584543e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
      "         Dropout2d-3             [-1, 20, 8, 8]               0\n",
      "            Linear-4                   [-1, 50]          16,050\n",
      "            Linear-5                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.15\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/4020281764.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d077a-2382-44f3-86ae-e68455ee4b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
