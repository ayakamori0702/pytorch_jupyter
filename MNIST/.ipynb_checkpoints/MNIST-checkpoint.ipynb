{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfaa12c-cab1-4be3-8099-3e4df70b297a",
   "metadata": {},
   "source": [
    "https://euske.github.io/introdl/lec6/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999bb1fd-ee93-4a47-aeef-cc2e25737907",
   "metadata": {},
   "source": [
    "GPU は CPU に比べて単純な処理しかできないが、CPU に比べて はるかに多くの処理を並列実行できるため、ある種のアルゴリズムに対しては CPU に比べて数倍〜数十倍の速度が出せる。ニューラルネットワークで 行われる演算はほとんどが足し算と掛け算なので、 とくに GPU で処理するのに向いているといえる.  \n",
    "NVIDIA が提供する CUDA 開発キットには GPU 用のコードが 生成できるよう拡張された C/C++コンパイラ (nvcc) が付属している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec31f914-275f-41f4-8557-da701177294b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1b8d2-eca3-4c95-9cd8-a79896ecba03",
   "metadata": {
    "tags": []
   },
   "source": [
    "機械学習における「テンソル」は「多次元配列」とほぼ同義である。 したがって Tensor型の基本機能も NumPy における ndarray型とほとんど同じであり、使い方もわざと ndarray型に似せてある。 ただし、以下のような機能が追加されている:\n",
    "\n",
    "Tensor上のデータは、CPU上の主記憶か、 あるいは GPU上のメモリのどちらに格納するか選ぶことができる。\n",
    "Tensor上の各数値は、 それが計算されたときの勾配 (grad) を保持することができる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74518fd8-06f7-4ffd-a3ce-3d240b35693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([1,2,3])  # x1はCPU上に作成される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0080c096-3a7e-4ae9-874c-fd2fc36b3c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48296838-2999-4b7c-9257-f039b44c9b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x1.to('cuda')          # x1をGPUに転送し、x2とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa03ab28-4918-4c97-8e04-a39246bbbc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b79e2153-384d-4794-a94f-dde8791374f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = x2.to('cpu')           # x2をCPUに転送し、x3とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdd674f8-6d73-4365-a806-1378c2eecd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c6d6db8-3430-4d9f-b175-5c06fcf929cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2*x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "328a2d3a-131b-48f3-89aa-c8b942f3a53e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx2\u001b[49m      \u001b[38;5;66;03m# CPU上とGPU上にあるデータは互いに計算できない。\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "x1*x2      # CPU上とGPU上にあるデータは互いに計算できない。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194b9c6d-2fcb-41d2-a6ed-a779c9c1d44f",
   "metadata": {},
   "source": [
    "## 演習6-5. CUDA を使ってテンソルを計算する (CUDA が使用可能な環境のみ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12dfedf2-b15b-4931-b075-e602e0dc7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# timeit: テンソルを二乗し、計算にかかった時間を表示する。\n",
    "def timeit(x):\n",
    "    t0 = time.time()\n",
    "    x = torch.mm(x, x)\n",
    "    dt = time.time() - t0\n",
    "    print(dt)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3c23c-09f7-40f9-817f-6583890ee981",
   "metadata": {},
   "source": [
    "CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30657b26-ad54-4895-9a5f-31b9ad6a33be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00898122787475586\n",
      "1.2357871532440186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2357871532440186"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100×100のランダムな行列を二乗する。\n",
    "x = torch.rand(100,100)\n",
    "timeit(x)\n",
    "# 10000×10000のランダムな行列を二乗する。\n",
    "x = torch.rand(10000,10000)\n",
    "timeit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad676310-50a7-4b10-a5ca-dfe0153bb495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45891499519348145\n",
      "0.0008440017700195312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0008440017700195312"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100×100のランダムな行列を二乗する。\n",
    "x = torch.rand(100,100).to('cuda')\n",
    "timeit(x)\n",
    "# 10000×10000のランダムな行列を二乗する。\n",
    "x = torch.rand(10000,10000).to('cuda')\n",
    "timeit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bafee4d-f6f8-45a4-9685-7f5e69da2f7e",
   "metadata": {},
   "source": [
    "## 3. PyTorch を使った MNIST の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de22e7a-5df8-40f5-ae53-90332b1da77b",
   "metadata": {},
   "source": [
    " PyTorch では、計算に使うテンソルが GPU 上にあれば GPU 上で計算が行われる。 そのため、以上のコードを GPU に対応させるのは容易である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67327b2d-9051-4b2c-a77d-b5a1f3ecd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# MNISTを処理するニューラルネットワーク。\n",
    "class MNISTNet(nn.Module):\n",
    "\n",
    "    # 各レイヤーの初期化。\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        # 畳み込み: 入力1チャンネル、出力10チャンネル、カーネル3×3。\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
    "        # Max Pooling: 1/2に縮める。\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # 畳み込み: 入力10チャンネル、出力20チャンネル、カーネル3×3。\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
    "        # Max Pooling: 1/2に縮める。\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        # 全接続 (fully connected): 入力500ノード、出力10ノード。\n",
    "        self.fc1 = nn.Linear(20*5*5, 10)\n",
    "        return\n",
    "\n",
    "    # 与えらえたミニバッチ x を処理する。\n",
    "    def forward(self, x):\n",
    "        # x: (N × 1 × 28 × 28)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        # x: (N × 10 × 26 × 26)\n",
    "        x = self.pool1(x)\n",
    "        # x: (N × 10 × 13 × 13)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        # x: (N × 20 × 11 × 11)\n",
    "        x = self.pool2(x)\n",
    "        # x: (N × 20 × 5 × 5)\n",
    "        x = x.reshape(len(x), 20*5*5)\n",
    "        # x: (N × 500)\n",
    "        x = self.fc1(x)\n",
    "        # x: (N × 10)\n",
    "        return x\n",
    "\n",
    "# 実際のインスタンスを作成。\n",
    "model = MNISTNet().to('cuda')  # ニューラルネットワークの重み・バイアスを GPU に転送する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf9c8781-220e-47b6-a7a3-ad9a70943ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "951982a9-a184-4cfc-b109-ed19d082924b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ミニバッチごとの訓練データを用意する。\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_images \u001b[38;5;241m=\u001b[39m \u001b[43mload_mnist\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/raw/train-images-idx3-ubyte.gz\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      3\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m load_mnist(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/raw/train-labels-idx1-ubyte.gz\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# ニューラルネットワークを訓練モードにする。\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_mnist' is not defined"
     ]
    }
   ],
   "source": [
    "# ミニバッチごとの訓練データを用意する。\n",
    "train_images = load_mnist('/raw/train-images-idx3-ubyte.gz') \n",
    "train_labels = load_mnist('/raw/train-labels-idx1-ubyte.gz') \n",
    "# ニューラルネットワークを訓練モードにする。\n",
    "model.train()\n",
    "# 最適化器と学習率を定義する。\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "n = 0\n",
    "# 各ミニバッチを処理する。\n",
    "for (images,labels) in zip(train_images, train_labels):\n",
    "    images = images.reshape(len(images), 1, 28, 28)\n",
    "    # 入力をfloat型のテンソルに変換。\n",
    "    inputs = torch.tensor(images).float()\n",
    "    # 正解をlong型のテンソルに変換。\n",
    "    targets = torch.tensor(labels).long()\n",
    "    # すべての勾配(.grad)をクリアしておく。\n",
    "    optimizer.zero_grad()\n",
    "    # 与えられたミニバッチをニューラルネットワークに処理させる。\n",
    "    output = model(inputs)\n",
    "    # 損失を計算する。\n",
    "    loss = F.cross_entropy(output, labels)\n",
    "    # 勾配を計算する。\n",
    "    loss.backward()\n",
    "    # 重み・バイアスを更新する。\n",
    "    optimizer.step()\n",
    "    n += len(images)\n",
    "    print(n, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9540f5-4cb5-44e0-8ab3-c7732b6a8ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
